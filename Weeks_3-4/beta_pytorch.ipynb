{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "artistic-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "from skimage.io import imsave\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "native-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "X = []\n",
    "for filename in os.listdir('Train/'):\n",
    "    X.append(np.array(Image.open('Train/'+filename).convert('RGB')))\n",
    "X = np.array(X, dtype=float)\n",
    "\n",
    "split = int(0.95*len(X))\n",
    "Xtrain = X[:split]\n",
    "Xtrain = 1.0/255*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fitting-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationNet_Beta(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationNet_Beta, self).__init__()\n",
    "        #fix this\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv7 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.conv10 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.conv11 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(32, 2, kernel_size=3, padding=1)\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = self.upsample1(x)\n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = self.upsample2(x)\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = torch.tanh(self.conv12(x))\n",
    "        x = self.upsample3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collected-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_train = rgb2lab(Xtrain)\n",
    "X_train = lab_train[:,:,:,0]\n",
    "Y_train = lab_train[:,:,:,1:] / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decimal-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6697\n",
      "Epoch [2/10], Loss: 0.0084\n",
      "Epoch [3/10], Loss: 0.0075\n",
      "Epoch [4/10], Loss: 0.0061\n",
      "Epoch [5/10], Loss: 0.0059\n",
      "Epoch [6/10], Loss: 0.0058\n",
      "Epoch [7/10], Loss: 0.0058\n",
      "Epoch [8/10], Loss: 0.0059\n",
      "Epoch [9/10], Loss: 0.0058\n",
      "Epoch [10/10], Loss: 0.0056\n"
     ]
    }
   ],
   "source": [
    "# Assuming Xtrain is a NumPy array containing training data\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "lab_train = rgb2lab(Xtrain)\n",
    "X_train = lab_train[:,:,:,0]\n",
    "Y_train = lab_train[:,:,:,1:] / 128\n",
    "X_train = X_train.reshape(10, 256, 256, 1)\n",
    "Y_train = Y_train.reshape(10, 256, 256, 2)\n",
    "Xtrain_tensor = torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2)  # Adjust dimension order\n",
    "Ytrain_tensor = torch.tensor(Y_train, dtype=torch.float32).permute(0, 3, 1, 2)  # Adjust dimension order\n",
    "\n",
    "# Define the PyTorch model, loss function, and optimizer\n",
    "model = ColorizationNet_Beta()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)\n",
    "\n",
    "\n",
    "# Image transformer (data augmentation)\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=20, shear=[-5, 5], scale=(0.8, 1.2)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "])\n",
    "\n",
    "# Custom dataset class for PyTorch\n",
    "class ColorizationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'image': self.X[idx], 'target': self.Y[idx]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "\n",
    "        return sample\n",
    "\n",
    "# Create DataLoader for batch training\n",
    "batch_size=2\n",
    "dataset = ColorizationDataset(Xtrain_tensor, Ytrain_tensor, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch['image'], batch['target']\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "usual-glasgow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0057\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "Xtest = X[split:]\n",
    "Xtest = 1.0/255*X\n",
    "lab_test = rgb2lab(Xtest)\n",
    "X_test = lab_test[:,:,:,0]\n",
    "Y_test = lab_test[:,:,:,1:] / 128\n",
    "X_test = X_test.reshape(10, 256, 256, 1)\n",
    "Y_test = Y_test.reshape(10, 256, 256, 2)\n",
    "Xtest_tensor = torch.tensor(X_test, dtype=torch.float32).permute(0, 3, 1, 2)  # Adjust dimension order\n",
    "Ytest_tensor = torch.tensor(Y_test, dtype=torch.float32).permute(0, 3, 1, 2)  # Adjust dimension order\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test data\n",
    "with torch.no_grad():\n",
    "    predictions_tensor = model(Xtest_tensor)\n",
    "\n",
    "# Flatten tensors\n",
    "Ytest_flat = torch.reshape(Ytest_tensor, (-1,)).numpy()\n",
    "predictions_flat = torch.reshape(predictions_tensor, (-1,)).numpy()\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(Ytest_flat, predictions_flat)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "entire-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "color_me = []\n",
    "for filename in os.listdir('Test/'):\n",
    "    color_me.append(np.array(Image.open('Test/'+filename).convert('RGB')))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = 1.0/255*color_me\n",
    "lab_cm = rgb2lab(color_me)\n",
    "X_in = lab_cm[:,:,:,0]\n",
    "X_in = X_in.reshape(8, 256, 256, 1)\n",
    "Xin_tensor = torch.tensor(X_in, dtype=torch.float32).permute(0, 3, 1, 2)  # Adjust dimension order\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test data\n",
    "with torch.no_grad():\n",
    "    Y_tensor = model(Xin_tensor)\n",
    "    output_numpy = Y_tensor.cpu().numpy()\n",
    "\n",
    "# Post-process and save images\n",
    "for i in range(8):\n",
    "    cur = np.zeros((output_numpy.shape[2], output_numpy.shape[3], 3))\n",
    "    cur[:,:,0] = X_in[i][:,:,0]\n",
    "    cur[:,:,1:] = (output_numpy[i] * 128).transpose(1, 2, 0)\n",
    "    output_rgb = (lab2rgb(cur) * 255).astype(np.uint8)\n",
    "    #input_rgb = (rgb2gray(lab2rgb(cur)) * 255).astype(np.uint8)\n",
    "    imsave(\"result/img_\"+str(i)+\".png\", output_rgb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
